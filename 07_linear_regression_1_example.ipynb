{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaqhDl1eyaV1JGh2tUEH5o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2023-sml/blob/main/07_linear_regression_1_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaQ8dO7PH-Ie"
      },
      "source": [
        "# 課題7\n",
        "\n",
        "* RMSEによって評価される予測性能を、良くして下さい\n",
        "* test setとそれ以外の部分の分割は、変えないでください\n",
        " * test set以外の部分をどう使うかは、自由です。\n",
        " * training setとvalidation setをくっつけて、交差検証をしていいです。\n",
        "* リッジ回帰とLassoを使ってもいいです\n",
        "* 高次多項式特徴量を使ってもいいです（cf. `sklearn.preprocessing.PolynomialFeatures`）\n",
        "* test setでのRMSEによる評価は最後に一回おこなうだけです"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCYz2LlyIJUW"
      },
      "source": [
        "import numpy as np\n",
        "from scipy import stats, special\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-8ombKtQkBM"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "from six.moves import urllib\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
        "  os.makedirs(housing_path, exist_ok=True)\n",
        "  tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "  urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "  housing_tgz = tarfile.open(tgz_path)\n",
        "  housing_tgz.extractall(path=housing_path)\n",
        "  housing_tgz.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewm8TpCMQj4X"
      },
      "source": [
        "fetch_housing_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qybD5v56JrtS"
      },
      "source": [
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "  csv_path = os.path.join(housing_path, \"housing.csv\")\n",
        "  return pd.read_csv(csv_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUzt-Kn9Ht91"
      },
      "source": [
        "（ここより上の詳細はフォローしなくてもいいいです。）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L5MBp4WQjeb"
      },
      "source": [
        "housing = load_housing_data()\n",
        "housing.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGJP-5qhNnoz"
      },
      "source": [
        "housing.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCM2yfWY2WUT"
      },
      "source": [
        "## 1) `ocean_proximity`を0/1の数値データへ変換"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4QjoTtjBQad"
      },
      "source": [
        "* pandasの`get_dummies`を使って、カテゴリカル変数`ocean_proximity`の値を0/1の数値データに変換する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac-bD3EfS9U6"
      },
      "source": [
        "housing_dummies = pd.get_dummies(housing['ocean_proximity'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RneEIPVscGsu"
      },
      "source": [
        "housing_dummies.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGCoKcQcLQJ"
      },
      "source": [
        "housing_num = housing.drop('ocean_proximity', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwkSYEuxcNLM"
      },
      "source": [
        "housing = pd.concat([housing_num, housing_dummies], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7QOByvAcTzg"
      },
      "source": [
        "housing.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M28tUOwREhEe"
      },
      "source": [
        "X = housing_num.drop('median_house_value', axis=1)\n",
        "y = housing_num[\"median_house_value\"].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ne-018U2upI"
      },
      "source": [
        "## 2) テストデータの欠損値を訓練データの中央値で埋める\n",
        "* 本当は、テストデータ全てについて予測をさせて評価すべきなので、欠損箇所を埋める。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPLyJcSqEu6i"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prhfKKrsB4cj"
      },
      "source": [
        "print(X_train.shape, X_valid.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "id": "cKAXMFeBKSJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid.info()"
      ],
      "metadata": {
        "id": "ADk9xu2NKTxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.info()"
      ],
      "metadata": {
        "id": "ICNHaDIfKIoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* テストセットで欠測値を含むインスタンスを単に脱落させたものも作っておく。"
      ],
      "metadata": {
        "id": "drka1ELoVtdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "na_index = X_test.isna().any(axis=1)\n",
        "X_test_original = X_test[~ na_index]\n",
        "y_test_original = y_test[~ na_index]"
      ],
      "metadata": {
        "id": "geDCvZHSVpdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnaQ5od7BUXk"
      },
      "source": [
        "* 欠測箇所を中央値で埋める\n",
        " * テストデータにだけ、total_bedroomsの値が欠けているエントリがある\n",
        " * ここでは訓練データの中央値で埋めることにする。\n",
        " * 訓練データだけから得られる情報を使って埋めているので、問題はない。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOB8AMN_ctbK"
      },
      "source": [
        "median_total_bedrooms = np.median(X_train.total_bedrooms[~ X_train.total_bedrooms.isna()])\n",
        "X_test.total_bedrooms = X_test.total_bedrooms.replace(np.nan, median_total_bedrooms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRgu9Htyer30"
      },
      "source": [
        "* 欠測箇所がなくなっていることを確認する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw214jfOeb0q"
      },
      "source": [
        "X_test.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) 目的変数の対数をとる\n",
        "* RMSEで評価するときに、np.exp()を使って元の値に戻す。"
      ],
      "metadata": {
        "id": "hgt4JggeTwj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.log(y_train)\n",
        "y_valid = np.log(y_valid)\n",
        "y_test = np.log(y_test)"
      ],
      "metadata": {
        "id": "k19ebknTRoPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txxiPG729s-f"
      },
      "source": [
        "## 4) 交差検証をしたいので訓練データと検証データを合併して一つにする"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6aBT-Yk7Jl2"
      },
      "source": [
        "X_train = pd.concat([X_train, X_valid])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBYlgGpv7bXb"
      },
      "source": [
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l09_Ey_a7TZr"
      },
      "source": [
        "y_train = pd.concat([y_train, y_valid])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAX9vt0F7cr0"
      },
      "source": [
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5rvTMsE9zWV"
      },
      "source": [
        "* 交差検証は10-foldで行う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UXamQ357GnJ"
      },
      "source": [
        "kf = KFold(n_splits=10, shuffle=True, random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRdwUiig2zzK"
      },
      "source": [
        "## 5) 特徴量を加工する\n",
        "* `sklearn.preprocessing.PolynomialFeatures`を使う"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVuDIUtH26p8"
      },
      "source": [
        "### 5-1) 比較のためにまず元データのまま交差検証を行なう"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 正則化なしの線形回帰"
      ],
      "metadata": {
        "id": "poXgu6w4KmxH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPy58KHFXJR-"
      },
      "source": [
        "reg = LinearRegression()\n",
        "rmses = []\n",
        "print(f'\\tRMSE:', end=' ')\n",
        "for train_index, valid_index in kf.split(X_train):\n",
        "  reg.fit(X_train.values[train_index], y_train.values[train_index])\n",
        "  y_valid_pred = reg.predict(X_train.values[valid_index])\n",
        "  y_valid_pred[y_valid_pred > y_train.values[train_index].max()] = y_train.values[train_index].max()\n",
        "  rmse = mean_squared_error(np.exp(y_train.values[valid_index]), np.exp(y_valid_pred), squared=False)\n",
        "  rmses.append(rmse)\n",
        "  print(f'{rmse:.3f}', end=', ')\n",
        "print()\n",
        "rmses = np.array(rmses)\n",
        "print(f'mean RMSE: {rmses.mean():.1f} ({rmses.std():.1f})')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Ridge回帰"
      ],
      "metadata": {
        "id": "rfiP91oRJkGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for alpha in 10.0 ** np.arange(-3, 4):\n",
        "  reg = Ridge(alpha=alpha, random_state=42)\n",
        "  rmses = []\n",
        "  print(f'\\tRMSE:', end=' ')\n",
        "  for train_index, valid_index in kf.split(X_train):\n",
        "    reg.fit(X_train.values[train_index], y_train.values[train_index])\n",
        "    y_valid_pred = reg.predict(X_train.values[valid_index])\n",
        "    y_valid_pred[y_valid_pred > y_train.values[train_index].max()] = y_train.values[train_index].max()\n",
        "    rmse = mean_squared_error(np.exp(y_train.values[valid_index]), np.exp(y_valid_pred), squared=False)\n",
        "    rmses.append(rmse)\n",
        "    print(f'{rmse:.3f}', end=', ')\n",
        "  print()\n",
        "  rmses = np.array(rmses)\n",
        "  print(f'alpha={alpha:.1e} | mean RMSE: {rmses.mean():.1f} ({rmses.std():.1f})')"
      ],
      "metadata": {
        "id": "L3s5AT4NJjVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Lasso"
      ],
      "metadata": {
        "id": "uTWFS1AhKbSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for alpha in 10.0 ** np.arange(-3, 4):\n",
        "  reg = Lasso(alpha=alpha, random_state=42)\n",
        "  rmses = []\n",
        "  print(f'\\tRMSE:', end=' ')\n",
        "  for train_index, valid_index in kf.split(X_train):\n",
        "    reg.fit(X_train.values[train_index], y_train.values[train_index])\n",
        "    y_valid_pred = reg.predict(X_train.values[valid_index])\n",
        "    y_valid_pred[y_valid_pred > y_train.values[train_index].max()] = y_train.values[train_index].max()\n",
        "    rmse = mean_squared_error(np.exp(y_train.values[valid_index]), np.exp(y_valid_pred), squared=False)\n",
        "    rmses.append(rmse)\n",
        "    print(f'{rmse:.3f}', end=', ')\n",
        "  print()\n",
        "  rmses = np.array(rmses)\n",
        "  print(f'alpha={alpha:.1e} | mean RMSE: {rmses.mean():.1f} ({rmses.std():.1f})')"
      ],
      "metadata": {
        "id": "1YFyvYImKa02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAO-C7gC3Bae"
      },
      "source": [
        "### 5-2) 2次の項を追加する"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 正則化なしの線形回帰"
      ],
      "metadata": {
        "id": "V7LE_BK9OLeZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytpOCLjt0QTm"
      },
      "source": [
        "poly = PolynomialFeatures(2)\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "reg = LinearRegression()\n",
        "rmses = []\n",
        "print(f'\\tRMSE:', end=' ')\n",
        "for train_index, valid_index in kf.split(X_train):\n",
        "  X_train_transformed = poly.fit_transform(scaler.fit_transform(X_train.values[train_index]))\n",
        "  X_valid_transformed = poly.transform(scaler.transform(X_train.values[valid_index]))\n",
        "  X_train_transformed = poly.fit_transform(X_train.values[train_index])\n",
        "  X_valid_transformed = poly.transform(X_train.values[valid_index])\n",
        "  reg.fit(X_train_transformed, y_train.values[train_index])\n",
        "  y_valid_pred = reg.predict(X_valid_transformed)\n",
        "  y_valid_pred[y_valid_pred > y_train.values[train_index].max()] = y_train.values[train_index].max()\n",
        "  rmse = mean_squared_error(np.exp(y_train.values[valid_index]), np.exp(y_valid_pred), squared=False)\n",
        "  rmses.append(rmse)\n",
        "  print(f'{rmse:.1f}', end=', ')\n",
        "print()\n",
        "rmses = np.array(rmses)\n",
        "print(f'mean RMSE: {rmses.mean():.1f} ({rmses.std():.1f})')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(2)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "reg = LinearRegression()\n",
        "rmses = []\n",
        "print(f'\\tRMSE:', end=' ')\n",
        "for train_index, valid_index in kf.split(X_train):\n",
        "  X_train_transformed = poly.fit_transform(scaler.fit_transform(X_train.values[train_index]))\n",
        "  X_valid_transformed = poly.transform(scaler.transform(X_train.values[valid_index]))\n",
        "  X_train_transformed = poly.fit_transform(X_train.values[train_index])\n",
        "  X_valid_transformed = poly.transform(X_train.values[valid_index])\n",
        "  reg.fit(X_train_transformed, y_train.values[train_index])\n",
        "  y_valid_pred = reg.predict(X_valid_transformed)\n",
        "  y_valid_pred[y_valid_pred > y_train.values[train_index].max()] = y_train.values[train_index].max()\n",
        "  rmse = mean_squared_error(np.exp(y_train.values[valid_index]), np.exp(y_valid_pred), squared=False)\n",
        "  rmses.append(rmse)\n",
        "  print(f'{rmse:.1f}', end=', ')\n",
        "print()\n",
        "rmses = np.array(rmses)\n",
        "print(f'mean RMSE: {rmses.mean():.1f} ({rmses.std():.1f})')"
      ],
      "metadata": {
        "id": "tEgTGWiDOcU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Ridge回帰"
      ],
      "metadata": {
        "id": "R3RUNuTqOKI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(2)\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "for alpha in 10.0 ** np.arange(-5, 3):\n",
        "  reg = Ridge(alpha=alpha, random_state=42)\n",
        "  rmses = []\n",
        "  print('\\tRMSE:', end=' ')\n",
        "  for train_index, valid_index in kf.split(X_train):\n",
        "    X_train_transformed = poly.fit_transform(scaler.fit_transform(X_train.values[train_index]))\n",
        "    X_valid_transformed = poly.transform(scaler.transform(X_train.values[valid_index]))\n",
        "    reg.fit(X_train_transformed, y_train.values[train_index])\n",
        "    y_valid_pred = reg.predict(X_valid_transformed)\n",
        "    y_valid_pred[y_valid_pred > y_train.values[train_index].max()] = y_train.values[train_index].max()\n",
        "    rmse = mean_squared_error(np.exp(y_train.values[valid_index]), np.exp(y_valid_pred), squared=False)\n",
        "    rmses.append(rmse)\n",
        "    print(f'{rmse:.3f}', end=', ')\n",
        "  print()\n",
        "  rmses = np.array(rmses)\n",
        "  print(f'alpha={alpha:.1e} | mean RMSE: {rmses.mean():.1f} ({rmses.std():.1f})')"
      ],
      "metadata": {
        "id": "4zOsdwrDKw0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(2)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for alpha in 10.0 ** np.arange(-5, 3):\n",
        "  reg = Ridge(alpha=alpha, random_state=42)\n",
        "  rmses = []\n",
        "  print('\\tRMSE:', end=' ')\n",
        "  for train_index, valid_index in kf.split(X_train):\n",
        "    X_train_transformed = poly.fit_transform(scaler.fit_transform(X_train.values[train_index]))\n",
        "    X_valid_transformed = poly.transform(scaler.transform(X_train.values[valid_index]))\n",
        "    reg.fit(X_train_transformed, y_train.values[train_index])\n",
        "    y_valid_pred = reg.predict(X_valid_transformed)\n",
        "    y_valid_pred[y_valid_pred > y_train.values[train_index].max()] = y_train.values[train_index].max()\n",
        "    rmse = mean_squared_error(np.exp(y_train.values[valid_index]), np.exp(y_valid_pred), squared=False)\n",
        "    rmses.append(rmse)\n",
        "    print(f'{rmse:.3f}', end=', ')\n",
        "  print()\n",
        "  rmses = np.array(rmses)\n",
        "  print(f'alpha={alpha:.1e} | mean RMSE: {rmses.mean():.1f} ({rmses.std():.1f})')"
      ],
      "metadata": {
        "id": "k1_UWApQN_Pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Lasso"
      ],
      "metadata": {
        "id": "5HVeSkslOgrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(2)\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "for alpha in 10.0 ** np.arange(-5, 3):\n",
        "  reg = Lasso(alpha=alpha, random_state=42)\n",
        "  rmses = []\n",
        "  print('\\tRMSE:', end=' ')\n",
        "  for train_index, valid_index in kf.split(X_train):\n",
        "    X_train_transformed = poly.fit_transform(scaler.fit_transform(X_train.values[train_index]))\n",
        "    X_valid_transformed = poly.transform(scaler.transform(X_train.values[valid_index]))\n",
        "    reg.fit(X_train_transformed, y_train.values[train_index])\n",
        "    y_valid_pred = reg.predict(X_valid_transformed)\n",
        "    y_valid_pred[y_valid_pred > y_train.values[train_index].max()] = y_train.values[train_index].max()\n",
        "    rmse = mean_squared_error(np.exp(y_train.values[valid_index]), np.exp(y_valid_pred), squared=False)\n",
        "    rmses.append(rmse)\n",
        "    print(f'{rmse:.3f}', end=', ')\n",
        "  print()\n",
        "  rmses = np.array(rmses)\n",
        "  print(f'alpha={alpha:.1e} | mean RMSE: {rmses.mean():.1f} ({rmses.std():.1f})')"
      ],
      "metadata": {
        "id": "EW4V34HWOgQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(2)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for alpha in 10.0 ** np.arange(-5, 3):\n",
        "  reg = Lasso(alpha=alpha, random_state=42)\n",
        "  rmses = []\n",
        "  print('\\tRMSE:', end=' ')\n",
        "  for train_index, valid_index in kf.split(X_train):\n",
        "    X_train_transformed = poly.fit_transform(scaler.fit_transform(X_train.values[train_index]))\n",
        "    X_valid_transformed = poly.transform(scaler.transform(X_train.values[valid_index]))\n",
        "    reg.fit(X_train_transformed, y_train.values[train_index])\n",
        "    y_valid_pred = reg.predict(X_valid_transformed)\n",
        "    y_valid_pred[y_valid_pred > y_train.values[train_index].max()] = y_train.values[train_index].max()\n",
        "    rmse = mean_squared_error(np.exp(y_train.values[valid_index]), np.exp(y_valid_pred), squared=False)\n",
        "    rmses.append(rmse)\n",
        "    print(f'{rmse:.3f}', end=', ')\n",
        "  print()\n",
        "  rmses = np.array(rmses)\n",
        "  print(f'alpha={alpha:.1e} | mean RMSE: {rmses.mean():.1f} ({rmses.std():.1f})')"
      ],
      "metadata": {
        "id": "1uPxs47pOMa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Q7jD-v--3YM"
      },
      "source": [
        "### 5-3) 3次までの項を追加する"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 正則化なしの線形回帰"
      ],
      "metadata": {
        "id": "nEpvRbDnR8gk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUhMvNQ-_ANb"
      },
      "source": [
        "poly = PolynomialFeatures(3)\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "reg = LinearRegression()\n",
        "rmses = []\n",
        "print(f'\\tRMSE:', end=' ')\n",
        "for train_index, valid_index in kf.split(X_train):\n",
        "  X_train_transformed = poly.fit_transform(scaler.fit_transform(X_train.values[train_index]))\n",
        "  X_valid_transformed = poly.transform(scaler.transform(X_train.values[valid_index]))\n",
        "  reg.fit(X_train_transformed, y_train.values[train_index])\n",
        "  y_valid_pred = reg.predict(X_valid_transformed)\n",
        "  y_valid_pred[y_valid_pred > y_train.values[train_index].max()] = y_train.values[train_index].max()\n",
        "  rmse = mean_squared_error(np.exp(y_train.values[valid_index]), np.exp(y_valid_pred), squared=False)\n",
        "  rmses.append(rmse)\n",
        "  print(f'{rmse:.1f}', end=', ')\n",
        "print()\n",
        "rmses = np.array(rmses)\n",
        "print(f'mean RMSE: {rmses.mean():.1f} ({rmses.std():.1f})')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(3)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "reg = LinearRegression()\n",
        "rmses = []\n",
        "print(f'\\tRMSE:', end=' ')\n",
        "for train_index, valid_index in kf.split(X_train):\n",
        "  X_train_transformed = poly.fit_transform(scaler.fit_transform(X_train.values[train_index]))\n",
        "  X_valid_transformed = poly.transform(scaler.transform(X_train.values[valid_index]))\n",
        "  reg.fit(X_train_transformed, y_train.values[train_index])\n",
        "  y_valid_pred = reg.predict(X_valid_transformed)\n",
        "  y_valid_pred[y_valid_pred > y_train.values[train_index].max()] = y_train.values[train_index].max()\n",
        "  rmse = mean_squared_error(np.exp(y_train.values[valid_index]), np.exp(y_valid_pred), squared=False)\n",
        "  rmses.append(rmse)\n",
        "  print(f'{rmse:.1f}', end=', ')\n",
        "print()\n",
        "rmses = np.array(rmses)\n",
        "print(f'mean RMSE: {rmses.mean():.1f} ({rmses.std():.1f})')"
      ],
      "metadata": {
        "id": "RhBu0b1pNpAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Ridge回帰"
      ],
      "metadata": {
        "id": "pQIYkxNaSL95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(3)\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "for alpha in 10.0 ** np.arange(-5, 3):\n",
        "  reg = Ridge(alpha=alpha, random_state=42)\n",
        "  rmses = []\n",
        "  print('\\tRMSE:', end=' ')\n",
        "  for train_index, valid_index in kf.split(X_train):\n",
        "    X_train_transformed = scaler.fit_transform(poly.fit_transform(X_train.values[train_index]))\n",
        "    X_valid_transformed = scaler.transform(poly.transform(X_train.values[valid_index]))\n",
        "    reg.fit(X_train_transformed, y_train.values[train_index])\n",
        "    y_valid_pred = reg.predict(X_valid_transformed)\n",
        "    y_valid_pred[y_valid_pred > y_train.values[train_index].max()] = y_train.values[train_index].max()\n",
        "    rmse = mean_squared_error(np.exp(y_train.values[valid_index]), np.exp(y_valid_pred), squared=False)\n",
        "    rmses.append(rmse)\n",
        "    print(f'{rmse:.3f}', end=', ')\n",
        "  print()\n",
        "  rmses = np.array(rmses)\n",
        "  print(f'alpha={alpha:.1e} | mean RMSE: {rmses.mean():.1f} ({rmses.std():.1f})')"
      ],
      "metadata": {
        "id": "84tBcfg-SD9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(3)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for alpha in 10.0 ** np.arange(-5, 3):\n",
        "  reg = Ridge(alpha=alpha, random_state=42)\n",
        "  rmses = []\n",
        "  print('\\tRMSE:', end=' ')\n",
        "  for train_index, valid_index in kf.split(X_train):\n",
        "    X_train_transformed = scaler.fit_transform(poly.fit_transform(X_train.values[train_index]))\n",
        "    X_valid_transformed = scaler.transform(poly.transform(X_train.values[valid_index]))\n",
        "    reg.fit(X_train_transformed, y_train.values[train_index])\n",
        "    y_valid_pred = reg.predict(X_valid_transformed)\n",
        "    y_valid_pred[y_valid_pred > y_train.values[train_index].max()] = y_train.values[train_index].max()\n",
        "    rmse = mean_squared_error(np.exp(y_train.values[valid_index]), np.exp(y_valid_pred), squared=False)\n",
        "    rmses.append(rmse)\n",
        "    print(f'{rmse:.3f}', end=', ')\n",
        "  print()\n",
        "  rmses = np.array(rmses)\n",
        "  print(f'alpha={alpha:.1e} | mean RMSE: {rmses.mean():.1f} ({rmses.std():.1f})')"
      ],
      "metadata": {
        "id": "TfSTBQ6CTbBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5-4) 4次までの項を追加する"
      ],
      "metadata": {
        "id": "7m3t5XrbUI5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(4)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "reg = LinearRegression()\n",
        "rmses = []\n",
        "print(f'\\tRMSE:', end=' ')\n",
        "for train_index, valid_index in kf.split(X_train):\n",
        "  X_train_transformed = poly.fit_transform(scaler.fit_transform(X_train.values[train_index]))\n",
        "  X_valid_transformed = poly.transform(scaler.transform(X_train.values[valid_index]))\n",
        "  reg.fit(X_train_transformed, y_train.values[train_index])\n",
        "  y_valid_pred = reg.predict(X_valid_transformed)\n",
        "  y_valid_pred[y_valid_pred > y_train.values[train_index].max()] = y_train.values[train_index].max()\n",
        "  rmse = mean_squared_error(np.exp(y_train.values[valid_index]), np.exp(y_valid_pred), squared=False)\n",
        "  rmses.append(rmse)\n",
        "  print(f'{rmse:.1f}', end=', ')\n",
        "print()\n",
        "rmses = np.array(rmses)\n",
        "print(f'mean RMSE: {rmses.mean():.1f} ({rmses.std():.1f})')"
      ],
      "metadata": {
        "id": "9Q2hkW0yTOLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(4)\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "reg = LinearRegression()\n",
        "rmses = []\n",
        "print(f'\\tRMSE:', end=' ')\n",
        "for train_index, valid_index in kf.split(X_train):\n",
        "  X_train_transformed = poly.fit_transform(scaler.fit_transform(X_train.values[train_index]))\n",
        "  X_valid_transformed = poly.transform(scaler.transform(X_train.values[valid_index]))\n",
        "  reg.fit(X_train_transformed, y_train.values[train_index])\n",
        "  y_valid_pred = reg.predict(X_valid_transformed)\n",
        "  y_valid_pred[y_valid_pred > y_train.values[train_index].max()] = y_train.values[train_index].max()\n",
        "  rmse = mean_squared_error(np.exp(y_train.values[valid_index]), np.exp(y_valid_pred), squared=False)\n",
        "  rmses.append(rmse)\n",
        "  print(f'{rmse:.1f}', end=', ')\n",
        "print()\n",
        "rmses = np.array(rmses)\n",
        "print(f'mean RMSE: {rmses.mean():.1f} ({rmses.std():.1f})')"
      ],
      "metadata": {
        "id": "b5ICn7rlQ7zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(4)\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "for alpha in 10.0 ** np.arange(-5, 3):\n",
        "  reg = Ridge(alpha=alpha, random_state=42)\n",
        "  rmses = []\n",
        "  print('\\tRMSE:', end=' ')\n",
        "  for train_index, valid_index in kf.split(X_train):\n",
        "    X_train_transformed = poly.fit_transform(scaler.fit_transform(X_train.values[train_index]))\n",
        "    X_valid_transformed = poly.transform(scaler.transform(X_train.values[valid_index]))\n",
        "    reg.fit(X_train_transformed, y_train.values[train_index])\n",
        "    y_valid_pred = reg.predict(X_valid_transformed)\n",
        "    y_valid_pred[y_valid_pred > y_train.values[train_index].max()] = y_train.values[train_index].max()\n",
        "    rmse = mean_squared_error(np.exp(y_train.values[valid_index]), np.exp(y_valid_pred), squared=False)\n",
        "    rmses.append(rmse)\n",
        "    print(f'{rmse:.3f}', end=', ')\n",
        "  print()\n",
        "  rmses = np.array(rmses)\n",
        "  print(f'alpha={alpha:.1e} | mean RMSE: {rmses.mean():.1f} ({rmses.std():.1f})')"
      ],
      "metadata": {
        "id": "sOat8_DTRD88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(4)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for alpha in 10.0 ** np.arange(-5, 3):\n",
        "  reg = Ridge(alpha=alpha, random_state=42)\n",
        "  rmses = []\n",
        "  print('\\tRMSE:', end=' ')\n",
        "  for train_index, valid_index in kf.split(X_train):\n",
        "    X_train_transformed = poly.fit_transform(scaler.fit_transform(X_train.values[train_index]))\n",
        "    X_valid_transformed = poly.transform(scaler.transform(X_train.values[valid_index]))\n",
        "    reg.fit(X_train_transformed, y_train.values[train_index])\n",
        "    y_valid_pred = reg.predict(X_valid_transformed)\n",
        "    y_valid_pred[y_valid_pred > y_train.values[train_index].max()] = y_train.values[train_index].max()\n",
        "    rmse = mean_squared_error(np.exp(y_train.values[valid_index]), np.exp(y_valid_pred), squared=False)\n",
        "    rmses.append(rmse)\n",
        "    print(f'{rmse:.3f}', end=', ')\n",
        "  print()\n",
        "  rmses = np.array(rmses)\n",
        "  print(f'alpha={alpha:.1e} | mean RMSE: {rmses.mean():.1f} ({rmses.std():.1f})')"
      ],
      "metadata": {
        "id": "khOjzhrYPu84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(4)\n",
        "scaler = StandardScaler()\n",
        "scaler2 = StandardScaler()\n",
        "\n",
        "for alpha in 10.0 ** np.arange(-5, 3):\n",
        "  reg = Ridge(alpha=alpha, random_state=42)\n",
        "  rmses = []\n",
        "  print('\\tRMSE:', end=' ')\n",
        "  for train_index, valid_index in kf.split(X_train):\n",
        "    X_train_transformed = scaler2.fit_transform(poly.fit_transform(scaler.fit_transform(X_train.values[train_index])))\n",
        "    X_valid_transformed = scaler2.transform(poly.transform(scaler.transform(X_train.values[valid_index])))\n",
        "    reg.fit(X_train_transformed, y_train.values[train_index])\n",
        "    y_valid_pred = reg.predict(X_valid_transformed)\n",
        "    y_valid_pred[y_valid_pred > y_train.values[train_index].max()] = y_train.values[train_index].max()\n",
        "    rmse = mean_squared_error(np.exp(y_train.values[valid_index]), np.exp(y_valid_pred), squared=False)\n",
        "    rmses.append(rmse)\n",
        "    print(f'{rmse:.3f}', end=', ')\n",
        "  print()\n",
        "  rmses = np.array(rmses)\n",
        "  print(f'alpha={alpha:.1e} | mean RMSE: {rmses.mean():.1f} ({rmses.std():.1f})')"
      ],
      "metadata": {
        "id": "rr8y0tjBTbTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(4)\n",
        "scaler = MinMaxScaler()\n",
        "scaler2 = MinMaxScaler()\n",
        "\n",
        "for alpha in 10.0 ** np.arange(-5, 3):\n",
        "  reg = Ridge(alpha=alpha, random_state=42)\n",
        "  rmses = []\n",
        "  print('\\tRMSE:', end=' ')\n",
        "  for train_index, valid_index in kf.split(X_train):\n",
        "    X_train_transformed = scaler2.fit_transform(poly.fit_transform(scaler.fit_transform(X_train.values[train_index])))\n",
        "    X_valid_transformed = scaler2.transform(poly.transform(scaler.transform(X_train.values[valid_index])))\n",
        "    reg.fit(X_train_transformed, y_train.values[train_index])\n",
        "    y_valid_pred = reg.predict(X_valid_transformed)\n",
        "    y_valid_pred[y_valid_pred > y_train.values[train_index].max()] = y_train.values[train_index].max()\n",
        "    rmse = mean_squared_error(np.exp(y_train.values[valid_index]), np.exp(y_valid_pred), squared=False)\n",
        "    rmses.append(rmse)\n",
        "    print(f'{rmse:.3f}', end=', ')\n",
        "  print()\n",
        "  rmses = np.array(rmses)\n",
        "  print(f'alpha={alpha:.1e} | mean RMSE: {rmses.mean():.1f} ({rmses.std():.1f})')"
      ],
      "metadata": {
        "id": "-aBoK880SVgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(4)\n",
        "scaler = MinMaxScaler()\n",
        "scaler2 = MinMaxScaler()\n",
        "\n",
        "for alpha in 10.0 ** np.arange(-9, -5):\n",
        "  reg = Ridge(alpha=alpha, random_state=42)\n",
        "  rmses = []\n",
        "  print('\\tRMSE:', end=' ')\n",
        "  for train_index, valid_index in kf.split(X_train):\n",
        "    X_train_transformed = scaler2.fit_transform(poly.fit_transform(scaler.fit_transform(X_train.values[train_index])))\n",
        "    X_valid_transformed = scaler2.transform(poly.transform(scaler.transform(X_train.values[valid_index])))\n",
        "    reg.fit(X_train_transformed, y_train.values[train_index])\n",
        "    y_valid_pred = reg.predict(X_valid_transformed)\n",
        "    y_valid_pred[y_valid_pred > y_train.values[train_index].max()] = y_train.values[train_index].max()\n",
        "    rmse = mean_squared_error(np.exp(y_train.values[valid_index]), np.exp(y_valid_pred), squared=False)\n",
        "    rmses.append(rmse)\n",
        "    print(f'{rmse:.3f}', end=', ')\n",
        "  print()\n",
        "  rmses = np.array(rmses)\n",
        "  print(f'alpha={alpha:.1e} | mean RMSE: {rmses.mean():.1f} ({rmses.std():.1f})')"
      ],
      "metadata": {
        "id": "8HaYb-W6TUEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(4)\n",
        "scaler = StandardScaler()\n",
        "scaler2 = MinMaxScaler()\n",
        "\n",
        "for alpha in 10.0 ** np.arange(-7, 1):\n",
        "  reg = Ridge(alpha=alpha, random_state=42)\n",
        "  rmses = []\n",
        "  print('\\tRMSE:', end=' ')\n",
        "  for train_index, valid_index in kf.split(X_train):\n",
        "    X_train_transformed = scaler2.fit_transform(poly.fit_transform(scaler.fit_transform(X_train.values[train_index])))\n",
        "    X_valid_transformed = scaler2.transform(poly.transform(scaler.transform(X_train.values[valid_index])))\n",
        "    reg.fit(X_train_transformed, y_train.values[train_index])\n",
        "    y_valid_pred = reg.predict(X_valid_transformed)\n",
        "    y_valid_pred[y_valid_pred > y_train.values[train_index].max()] = y_train.values[train_index].max()\n",
        "    rmse = mean_squared_error(np.exp(y_train.values[valid_index]), np.exp(y_valid_pred), squared=False)\n",
        "    rmses.append(rmse)\n",
        "    print(f'{rmse:.3f}', end=', ')\n",
        "  print()\n",
        "  rmses = np.array(rmses)\n",
        "  print(f'alpha={alpha:.1e} | mean RMSE: {rmses.mean():.1f} ({rmses.std():.1f})')"
      ],
      "metadata": {
        "id": "3X_iFV1xTtL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(4)\n",
        "scaler = MinMaxScaler()\n",
        "scaler2 = StandardScaler()\n",
        "\n",
        "for alpha in 10.0 ** np.arange(-7, 1):\n",
        "  reg = Ridge(alpha=alpha, random_state=42)\n",
        "  rmses = []\n",
        "  print('\\tRMSE:', end=' ')\n",
        "  for train_index, valid_index in kf.split(X_train):\n",
        "    X_train_transformed = scaler2.fit_transform(poly.fit_transform(scaler.fit_transform(X_train.values[train_index])))\n",
        "    X_valid_transformed = scaler2.transform(poly.transform(scaler.transform(X_train.values[valid_index])))\n",
        "    reg.fit(X_train_transformed, y_train.values[train_index])\n",
        "    y_valid_pred = reg.predict(X_valid_transformed)\n",
        "    y_valid_pred[y_valid_pred > y_train.values[train_index].max()] = y_train.values[train_index].max()\n",
        "    rmse = mean_squared_error(np.exp(y_train.values[valid_index]), np.exp(y_valid_pred), squared=False)\n",
        "    rmses.append(rmse)\n",
        "    print(f'{rmse:.3f}', end=', ')\n",
        "  print()\n",
        "  rmses = np.array(rmses)\n",
        "  print(f'alpha={alpha:.1e} | mean RMSE: {rmses.mean():.1f} ({rmses.std():.1f})')"
      ],
      "metadata": {
        "id": "AV9CN6ZvT7w6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5-5) 乱数のシードを変える"
      ],
      "metadata": {
        "id": "pOQ9eMByV_22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `random_state`の値を変更した10-fold交差検証をおこなって、似たような性能が出せるか、確認する。"
      ],
      "metadata": {
        "id": "Qrtkd1kLUmCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=10, shuffle=True, random_state=23456)\n",
        "\n",
        "poly = PolynomialFeatures(4)\n",
        "scaler = MinMaxScaler()\n",
        "scaler2 = MinMaxScaler()\n",
        "\n",
        "for alpha in 10.0 ** np.arange(-8, 0):\n",
        "  reg = Ridge(alpha=alpha, random_state=42)\n",
        "  rmses = []\n",
        "  print('\\tRMSE:', end=' ')\n",
        "  for train_index, valid_index in kf.split(X_train):\n",
        "    X_train_transformed = scaler2.fit_transform(poly.fit_transform(scaler.fit_transform(X_train.values[train_index])))\n",
        "    X_valid_transformed = scaler2.transform(poly.transform(scaler.transform(X_train.values[valid_index])))\n",
        "    reg.fit(X_train_transformed, y_train.values[train_index])\n",
        "    y_valid_pred = reg.predict(X_valid_transformed)\n",
        "    y_valid_pred[y_valid_pred > y_train.values[train_index].max()] = y_train.values[train_index].max()\n",
        "    rmse = mean_squared_error(np.exp(y_train.values[valid_index]), np.exp(y_valid_pred), squared=False)\n",
        "    rmses.append(rmse)\n",
        "    print(f'{rmse:.3f}', end=', ')\n",
        "  print()\n",
        "  rmses = np.array(rmses)\n",
        "  print(f'alpha={alpha:.1e} | mean RMSE: {rmses.mean():.1f} ({rmses.std():.1f})')"
      ],
      "metadata": {
        "id": "TktYJr1GUJB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `alpha=1.0e-05`で良さそう。"
      ],
      "metadata": {
        "id": "3lm779wNYs4-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrGdLCb-4Kpw"
      },
      "source": [
        "## 6) チューニング済みの手法をテストデータ上で評価"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V7G4CR0AP2K"
      },
      "source": [
        "poly = PolynomialFeatures(4)\n",
        "scaler = MinMaxScaler()\n",
        "scaler2 = MinMaxScaler()\n",
        "\n",
        "X_train_transformed = scaler2.fit_transform(poly.fit_transform(scaler.fit_transform(X_train)))\n",
        "X_test_transformed = scaler2.transform(poly.transform(scaler.transform(X_test)))\n",
        "\n",
        "reg = Ridge(alpha=1.0e-5, random_state=42)\n",
        "reg.fit(X_train_transformed, y_train)\n",
        "y_test_pred = reg.predict(X_test_transformed)\n",
        "y_test_pred[y_test_pred > y_train.max()] = y_train.max()\n",
        "rmse = mean_squared_error(np.exp(y_test), np.exp(y_test_pred), squared=False)\n",
        "print(f'test RMSE: {rmse:.1f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 欠測箇所を含むインスタンスを脱落させて作ったテストセットで評価する。"
      ],
      "metadata": {
        "id": "GDMImyolYSrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(4)\n",
        "scaler = MinMaxScaler()\n",
        "scaler2 = MinMaxScaler()\n",
        "\n",
        "X_train_transformed = scaler2.fit_transform(poly.fit_transform(scaler.fit_transform(X_train)))\n",
        "X_test_transformed = scaler2.transform(poly.transform(scaler.transform(X_test_original)))\n",
        "\n",
        "reg = Ridge(alpha=1.0e-5, random_state=42)\n",
        "reg.fit(X_train_transformed, y_train)\n",
        "y_test_pred = reg.predict(X_test_transformed)\n",
        "y_test_pred[y_test_pred > y_train.max()] = y_train.max()\n",
        "rmse = mean_squared_error(y_test_original, np.exp(y_test_pred), squared=False)\n",
        "print(f'test RMSE: {rmse:.1f}')"
      ],
      "metadata": {
        "id": "jC5w3iepX2xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 何の工夫もない線形回帰だとテスト性能がどうなるか、確認しておく。"
      ],
      "metadata": {
        "id": "CvdL8oaOVOAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg = LinearRegression()\n",
        "reg.fit(X_train, y_train)\n",
        "y_test_pred = reg.predict(X_test)\n",
        "y_test_pred[y_test_pred > y_train.max()] = y_train.max()\n",
        "rmse = mean_squared_error(np.exp(y_test), np.exp(y_test_pred), squared=False)\n",
        "print(f'test RMSE: {rmse:.1f}')"
      ],
      "metadata": {
        "id": "PNeVz_IJUs9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 欠測箇所を含むインスタンスを脱落させて作ったテストセットで評価する。"
      ],
      "metadata": {
        "id": "P5YJxMByYhZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg = LinearRegression()\n",
        "reg.fit(X_train, y_train)\n",
        "y_test_pred = reg.predict(X_test_original)\n",
        "y_test_pred[y_test_pred > y_train.max()] = y_train.max()\n",
        "rmse = mean_squared_error(y_test_original, np.exp(y_test_pred), squared=False)\n",
        "print(f'test RMSE: {rmse:.1f}')"
      ],
      "metadata": {
        "id": "6Y2YOmrRVMtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A2aBgvfgYL2C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}